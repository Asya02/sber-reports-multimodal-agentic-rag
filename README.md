# Multimodal self-reflective RAG on Sberbank year reports

## Описание проекта

Этот проект представляет собой чат-бота, который отвечает на вопросы по годовому отчету Сбера за 2023 год, при необходимости модифицируя пользовательский запрос и добавляя в контекст результаты, найденные тулом Tavily Search. Идея решения взята из статьи "[Corrective Retrieval Augmented Generation](https://arxiv.org/pdf/2401.15884)" и адаптирована для использования в данном контексте. 

Решение реализовано с использованием фреймворка **LangGraph** и схема графа выглядит следующим образом:
![Граф](./assets/graph.png)


## Структура проекта

Проект разделен на несколько ключевых директорий:

```plaintext
sber-reports-rag/
│
├── data/                      # Папка с данными
│   ├── interim/               # Промежуточные данные
│   │   ├── images/            # Изображения, извлеченные из pdf
│   │   ├── texts/             # Тексты с описаниями изображений
│   ├── raw/                   # Сырые данные (сам отчёт в pdf)
│   ├── vectorstore/           # Хранилище с векторами документов
│
├── notebooks/                 # Jupyter-ноутбуки с экспериментами
│
├── sber_reports_rag/          # Основной исходный код проекта
│   ├── backend/               # Логика работы бэкенда 
│   ├── data/                  # Логика предобработки данных
│   ├── utils/                 # Вспомогательные функции и промпты
│   ├── streamlit_app.py       # Реализация UI
│
├── assets/                    # Медиа-файлы для проекта
│
└── README.md                  # Описание проекта
```

## Подготовка данных и создание векторного хранилища

1. **Сбор документов**:
   Сначала необходимо исходный файл с названием `Сбер 2023.pdf` положить в `data/interim/texts/`. 

2. **Создание векторного хранилища**:
   После этого, выполните следующую команду для создания векторного хранилища:

   ```bash
   python -m sber_reports_rag/data/data_preparation.py
   ```

   Этот шаг создаст векторную базу и сохранит эмбеддинги документов в папке `data/vectorstore/`.

## Запуск приложения

Для запуска Streamlit приложения выполните следующие шаги:

1. Убедитесь, что все зависимости установлены:

   ```bash
   pip install -r requirements.txt
   ```

2. Запустите приложение Streamlit:

   ```bash
   streamlit run sber_reports_rag/streamlit_app.py
   ```

3. Перейдите в браузер и откройте локальный хост по адресу:

   ```plaintext
   http://localhost:8501
   ```

   Теперь вы сможете взаимодействовать с чат-ботом и задавать вопросы.

## Пример использования

После запуска приложения вы сможете задать свой вопрос, и система сгенерирует ответ на основе информации, найденной в документах или в случае, если после 3х переформулировок запроса ничего подходящего не сгенерировалось, то найденной с использованием движка TavilySearch. Ниже приведены примеры взаимодействия:

1. Чат-бот верно отвечает на вопросы по pdf документу
   
   ![Первый пример](./assets/example1.png)

2. Чат-бот не галлюцинирует при ответах на вопросы, когда информации нет.
   ![Второй пример](./assets/example_hall.png)

3. Чат-бот использует движок TavilySearch для ответов на прочие вопросы
   ![Третий пример](./assets/example_tavily.png)

Также в проекте пока что просто печатаются в терминал логи, по которым можно понять, какая именно стадия сейчас обрабатывается, с какой попытки получен ответ на вопрос и т.д.
   ![Логирование пример](./assets/example_logs.png)

## Основные проблемы и решения

### Обработка исходного PDF документа

Одной из ключевых проблем в проекте стала работа с исходным PDF документом, который содержал большое количество изображений. На первых 20 страницах документа было уже 37 графических элементов (изображения, схемы, диаграммы и т.д.). 

### Проблема интерпретации информации

Важная информация зачастую была представлена как комбинация текста и изображений. Например, числовые данные могли быть отображены на одной картинке, а их пояснения — на другой, либо вообще в текстовой части. Такая разрозненная структура усложняла задачу правильного объединения данных при их обработке и интерпретации.

Изначально я пробовала использовать библиотеку `unstructured` для обработки таких документов, но из-за сложности сопоставления текста и изображений это не дало удовлетворительных результатов. Более подробное описание экспериментов сохранены в ноутбуке с названием `multimodal-rag-unstructured.ipynb`.

### Принятое решение

В итоге было принято решение отказаться от подхода, основанного на раздельной обработке текстов и изображений, и перейти к мультимодальному подходу. Каждая страница PDF-документа стала рассматриваться как единое целое, аналогичное слайду презентации. Я подавала каждую страницу целиком на вход мультимодальной модели, которая самостоятельно формировала качественное описание содержания страницы в формате markdown. Это позволило лучше интерпретировать контекст и связать текстовые и визуальные элементы на каждой странице.

Такой подход обеспечил более корректную обработку визуально насыщенных страниц и позволил получить точные и контекстно обоснованные описания.
