{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da669278-fbac-44f3-9f8a-bacc93fd0a5a",
   "metadata": {},
   "source": [
    "# PDF processing as images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0f6e6b-345d-4aae-9cef-1606cf5f8a05",
   "metadata": {},
   "source": [
    "Посмотрев на данные и увидев, что уже на 20 первых страницах изображений встречается 37 штук, а ещё и из-за того, что это презенташка, текст нормально не собирается - не понятно, какая цифра к чему относится, я решила сделать предобработку данных чуть иначе - использовать мульмодальную llm для всех слайдов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68034c2e-acc2-4f0a-abed-0b5e1bf4cb9c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сохранена страница 1 как ../data/interim/images/page_1.png\n",
      "Сохранена страница 2 как ../data/interim/images/page_2.png\n",
      "Сохранена страница 3 как ../data/interim/images/page_3.png\n",
      "Сохранена страница 4 как ../data/interim/images/page_4.png\n",
      "Сохранена страница 5 как ../data/interim/images/page_5.png\n",
      "Сохранена страница 6 как ../data/interim/images/page_6.png\n",
      "Сохранена страница 7 как ../data/interim/images/page_7.png\n",
      "Сохранена страница 8 как ../data/interim/images/page_8.png\n",
      "Сохранена страница 9 как ../data/interim/images/page_9.png\n",
      "Сохранена страница 10 как ../data/interim/images/page_10.png\n",
      "Сохранена страница 11 как ../data/interim/images/page_11.png\n",
      "Сохранена страница 12 как ../data/interim/images/page_12.png\n",
      "Сохранена страница 13 как ../data/interim/images/page_13.png\n",
      "Сохранена страница 14 как ../data/interim/images/page_14.png\n",
      "Сохранена страница 15 как ../data/interim/images/page_15.png\n",
      "Сохранена страница 16 как ../data/interim/images/page_16.png\n",
      "Сохранена страница 17 как ../data/interim/images/page_17.png\n",
      "Сохранена страница 18 как ../data/interim/images/page_18.png\n",
      "Сохранена страница 19 как ../data/interim/images/page_19.png\n",
      "Сохранена страница 20 как ../data/interim/images/page_20.png\n"
     ]
    }
   ],
   "source": [
    "from pdf2image import convert_from_path\n",
    "import os\n",
    "\n",
    "def save_pdf_pages_as_images(pdf_path, output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Конвертируем страницы PDF в изображения\n",
    "    images = convert_from_path(pdf_path)  \n",
    "    \n",
    "    # Сохраняем каждую страницу как изображение\n",
    "    for i, image in enumerate(images):\n",
    "        image_path = os.path.join(output_dir, f'page_{i + 1}.png')\n",
    "        image.save(image_path, 'PNG')\n",
    "        print(f'Сохранена страница {i + 1} как {image_path}')\n",
    "\n",
    "# Пример использования функции\n",
    "pdf_path = '../data/raw/Сбер 2023-1-20.pdf'\n",
    "output_dir = '../data/interim/images/'\n",
    "save_pdf_pages_as_images(pdf_path, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbd546a8-6540-4746-9306-c9baa377e28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import os\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "# Функция кодирования изображения в формат base64\n",
    "def encode_image(image_path):\n",
    "    \"\"\"\n",
    "    Функция для кодирования изображения в формат base64.\n",
    "\n",
    "    Аргументы:\n",
    "    image_path: Строка, путь к изображению, которое нужно закодировать.\n",
    "\n",
    "    Возвращает:\n",
    "    Закодированное в формате base64 изображение в виде строки.\n",
    "    \"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        # Читаем файл изображения в бинарном режиме и кодируем в base64\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "# Функция для суммаризации изображения с использованием модели GPT\n",
    "def image_summarize(img_base64, prompt):\n",
    "    \"\"\"\n",
    "    Функция для получения суммаризации изображения с использованием GPT модели.\n",
    "\n",
    "    Аргументы:\n",
    "    img_base64: Строка, изображение закодированное в формате base64.\n",
    "    prompt: Строка, запрос для модели GPT, содержащий инструкцию для суммаризации изображения.\n",
    "\n",
    "    Возвращает:\n",
    "    Суммаризация изображения, возвращенная моделью GPT.\n",
    "    \"\"\"\n",
    "    chat = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "    msg = chat.invoke(\n",
    "        [\n",
    "            HumanMessage(\n",
    "                content=[\n",
    "                    {\"type\": \"text\", \"text\": prompt},  # Запрос для модели\n",
    "                    {\n",
    "                        \"type\": \"image_url\",  # Тип содержимого - изображение\n",
    "                        \"image_url\": {\"url\": f\"data:image/png;base64,{img_base64}\"},  # Изображение в формате base64\n",
    "                    },\n",
    "                ]\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    # Возвращаем содержимое ответа от модели\n",
    "    return msg.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86e7eae0-f3e5-45e8-b378-34d8b5c9bd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text_from_image(img_path):\n",
    "    prompt = \"\"\"Опиши ключевую информацию, которая представлена на изображении. Описание должно быть конкретным и точным. Обрати особое внимание на графики, диаграммы или визуальные элементы, которые можно проанализировать.\n",
    "    Очень важно не упустить детали. Ответь в формате Markdown.\"\"\"\n",
    "    base64_image = encode_image(img_path)\n",
    "    return image_summarize(base64_image, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6886c68f-3781-4014-9f14-db9d1db16359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "openai:  ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"openai: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac63ee7d-dcf0-4c32-a32d-fd04125a196f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = prepare_text_from_image(\"../data/interim/images/page_11.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c8063f5-854b-42e0-a5d6-bf0906577986",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Ключевая информация о Сбер\n",
      "\n",
      "## Общие данные\n",
      "- **Розничные клиенты**: \n",
      "  - 108,5 млн активных\n",
      "  - 81,9 млн MAU Сбербанк Онлайн\n",
      "  - 10,0 млн пользователей подписки СберПрайм\n",
      "- **Корпоративные клиенты**: \n",
      "  - 3,2 млн активных\n",
      "  - 2,8 млн MAU СберБизнес Онлайн\n",
      "- **Сотрудники**: 210,8 тыс.\n",
      "- **Офисы**: ~12,0 тыс.\n",
      "\n",
      "## Важные факты\n",
      "- **Сильнейший финансовый бренд в Европе** (по рейтингу Brand Finance)\n",
      "- **№ 1 по рыночной капитализации в России**: ~75 млрд долларов США\n",
      "- **Крупнейший эквайер в Европе** (по Nilson Report)\n",
      "- **Банк № 1** по чистой прибыли в Восточной Европе по итогам 2023 года\n",
      "\n",
      "## Трансформация Сбера\n",
      "1. **Надежный банк**: \n",
      "   - Лидер в депозитах физических лиц\n",
      "   - Крупнейшая сеть отделений среди банков в России\n",
      "   - Крупнейший транзакционный банк страны\n",
      "2. **Лидер в цифровом банкинге**:\n",
      "   - \"Лучшее банковское приложение\"\n",
      "   - Лучшие практики управления рисками\n",
      "   - Лучший клиентский опыт\n",
      "3. **Интегрированная технологическая экосистема**:\n",
      "   - Построение экосистем вокруг клиента с финансовыми и нефинансовыми сервисами\n",
      "4. **На пути к человекоцентричности**:\n",
      "   - Сбер — помощник человека в управлении настоящим и будущим, в том числе с помощью искусственного интеллекта нового поколения.\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59b5c404-2ad2-40e0-8db6-f96a8e8b4909",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Искусственный интеллект в 2023 году\n",
      "\n",
      "## Результаты AI-трансформации\n",
      "- **Финансовый эффект от внедрения ИИ в 2023 году**: 350+ млрд руб.\n",
      "- **Среднегодовой рост эффекта от ИИ (CAGR)** за 2020-2023 годы: 53%.\n",
      "- **Исследователи данных, аналитики данных, дата-инженеры и ML-инженеры**: 2,7 тыс. сотрудников.\n",
      "- **Модели ИИ, внедренные в бизнес-процессы банка**: 2 тыс. моделей.\n",
      "\n",
      "## Модели генеративного ИИ\n",
      "- **GigaChat**: сервис для взаимодействия с пользователями в формате диалога.\n",
      "  - **Количество пользователей**: 2,6 млн.\n",
      "- **Kandinsky**: модель для генерации высококачественных изображений по текстовому описанию.\n",
      "  - **Количество генераций**: 200+ млн изображений.\n",
      "- **Kandinsky Video**: первая в России модель для создания видео по текстовому описанию.\n",
      "- **OmniFusion**: мультимодальная модель для описания изображений (вместе с AIRI).\n",
      "\n",
      "## AI Journey\n",
      "- **Конференция AI Journey**: важное событие в мире ИИ, прошедшее в 2023 году.\n",
      "  - **Просмотры трансляции**: 150 млн.\n",
      "  - **Выступившие спикеры**: 200+.\n",
      "\n",
      "## Исследовательская деятельность\n",
      "- Сбер сотрудничает с вузами для развития кадрового потенциала и распространения компетенций среди специалистов в области ИИ.\n",
      "- **Статьи в научных журналах Q1 и выступления на конференциях A/A**: 93 научные статьи за 2023 год.\n",
      "- **R&D-специалисты в области ИИ**: 300+ сотрудников.\n",
      "\n",
      "## Подготовка ИИ-кадров\n",
      "- **Обучение по контенту, разработанному специалистами Сбера**: 200 тыс. студентов.\n",
      "- **Обучение на 13 совместных образовательных программах Сбера по AI**: 711 студентов.\n",
      "- **Участие в Уроке Цифры \"Искусственный интеллект в отраслях\"**: 2,8 млн школьников.\n"
     ]
    }
   ],
   "source": [
    "res2 = prepare_text_from_image(\"../data/interim/images/page_18.png\")\n",
    "print(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80513594-6fcd-40f0-b7fd-8a37b6f0bdbe",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Ключевая финансовая информация\n",
      "\n",
      "## Общие показатели\n",
      "- **Чистая прибыль**: 1 509 млрд руб. (в 2022 году: 288 млрд руб.)\n",
      "- **Рентабельность капитала (ROE)**: 25,3% (в 2022 году: 5,2%)\n",
      "- **Прибыль на акцию (EPS)**: 69,1 руб. (в 2022 году: 13,2 руб.)\n",
      "- **Собственные средства**: 6,6 трлн руб. (в 2022 году: 5,8 трлн руб.)\n",
      "\n",
      "## Доходы\n",
      "- **Чистый процентный доход**: 2 565 млрд руб. (рост на 36,8% по сравнению с предыдущим периодом)\n",
      "- **Чистый комиссионный доход**: 764 млрд руб. (рост на 9,4% по сравнению с предыдущим периодом)\n",
      "\n",
      "## Расходы\n",
      "- **Операционные расходы**: 924 млрд руб. (рост на 27,2% по сравнению с предыдущим периодом)\n",
      "- **Расходы на резервы**: 265 млрд руб.\n",
      "\n",
      "## Дополнительные показатели\n",
      "- **Чистая процентная маржа**: 5,98%\n",
      "- **Чистые комиссионные доходы к операционным доходам до вычета резервов**: 24,1%\n",
      "- **Расходы к доходам (CIR)**: 29,2%\n",
      "- **Стоимость риска (COR)**: 0,8 п.п.\n",
      "\n",
      "## Кредиты\n",
      "- **Корпоративные кредиты**: 23,3 трлн руб. (рост на 25,2% по сравнению с 2022 годом)\n",
      "- **Розничные кредиты**: 16,1 трлн руб. (рост на 29,3% по сравнению с 2022 годом)\n",
      "- **Средства корпоративных клиентов**: 13,8 трлн руб. (рост на 21,2% по сравнению с 2022 годом)\n",
      "- **Средства розничных клиентов**: 22,9 трлн руб. (рост на 23,8% по сравнению с 2022 годом)\n",
      "\n",
      "Эти показатели демонстрируют значительное улучшение финансовых результатов по сравнению с предыдущим годом.\n"
     ]
    }
   ],
   "source": [
    "res3 = prepare_text_from_image(\"../data/interim/images/page_20.png\")\n",
    "print(res3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "277a83e2-5a87-4426-8281-676af67b697d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Ключевая информация об отчете Сбербанка за 2023 год\n",
      "\n",
      "## Общая информация\n",
      "- **Название документа**: Годовой отчет ПАО «Сбербанк России» за 2023 год.\n",
      "- **Период отчета**: с 1 января по 31 декабря 2023 года.\n",
      "- **Содержание**: Отчет включает данные о результатах деятельности Сбербанка и его ESG-отчет.\n",
      "\n",
      "## Подход к отчету\n",
      "- **Законодательство**: Подготовлен в соответствии с законодательством Российской Федерации, включая:\n",
      "  - Федеральный закон от 26.12.1995 № 208-ФЗ «О акционерных обществах».\n",
      "  - Федеральный закон от 22.04.1996 № 39-ФЗ «О рынке ценных бумаг».\n",
      "  - Положение Банка России от 27.03.2020 № 714-П «О раскрытии информации эмитентами ценных бумаг».\n",
      "\n",
      "## Рекомендации и стандарты\n",
      "- **Применяемые принципы**:\n",
      "  - Принципы Глобального договора ООН.\n",
      "  - Цели устойчивого развития, принятые Генеральной Ассамблеей ООН в 2015 году.\n",
      "  - Принципы ответственной банковской деятельности (UNEP Finance Initiative).\n",
      "  - Методические рекомендации Минэкономразвития России для подготовки отчетности по устойчивому развитию.\n",
      "  - Стандарты МСФО (IFRS) по раскрытию информации в области устойчивого развития.\n",
      "\n",
      "## Важные даты\n",
      "- **Письмо Банка России**: Информационное письмо о раскрытии финансовыми организациями информации в области устойчивого развития от 13.07.2023.\n",
      "- **Решение Совета директоров**: О требованиях к раскрытию кредитными организациями отчетности.\n",
      "\n",
      "## Ссылки\n",
      "- Электронные версии отчетов доступны на сайте: [sberbank.ru](http://www.sberbank.ru).\n"
     ]
    }
   ],
   "source": [
    "res4 = prepare_text_from_image(\"../data/interim/images/page_2.png\")\n",
    "print(res4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e15b353-647a-4a3a-be16-63757a308a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1457"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c51e44db-d55c-4335-b136-a3ef8d117ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат для page_1.png сохранен в page_1.txt\n",
      "Результат для page_10.png сохранен в page_10.txt\n",
      "Результат для page_11.png сохранен в page_11.txt\n",
      "Результат для page_12.png сохранен в page_12.txt\n",
      "Результат для page_13.png сохранен в page_13.txt\n",
      "Результат для page_14.png сохранен в page_14.txt\n",
      "Результат для page_15.png сохранен в page_15.txt\n",
      "Результат для page_16.png сохранен в page_16.txt\n",
      "Результат для page_17.png сохранен в page_17.txt\n",
      "Результат для page_18.png сохранен в page_18.txt\n",
      "Результат для page_19.png сохранен в page_19.txt\n",
      "Результат для page_2.png сохранен в page_2.txt\n",
      "Результат для page_20.png сохранен в page_20.txt\n",
      "Результат для page_3.png сохранен в page_3.txt\n",
      "Результат для page_4.png сохранен в page_4.txt\n",
      "Результат для page_5.png сохранен в page_5.txt\n",
      "Результат для page_6.png сохранен в page_6.txt\n",
      "Результат для page_7.png сохранен в page_7.txt\n",
      "Результат для page_8.png сохранен в page_8.txt\n",
      "Результат для page_9.png сохранен в page_9.txt\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "def create_texts_from_images(images_dir_path, output_dir):\n",
    "    # Проверяем, существует ли папка для текстовых файлов, если нет, создаем её\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Проходим по каждому файлу в папке с изображениями\n",
    "    for image_filename in os.listdir(input_dir):\n",
    "        # Полный путь к изображению\n",
    "        image_path = os.path.join(input_dir, image_filename)\n",
    "\n",
    "        # Проверяем, что это изображение (например, файл с расширением PNG или JPG)\n",
    "        if image_filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "            # Открываем изображение, если оно действительно является изображением\n",
    "            try:\n",
    "                with Image.open(image_path):\n",
    "                    result = prepare_text_from_image(image_path)\n",
    "\n",
    "                    # Генерируем имя файла для текстового результата\n",
    "                    output_filename = os.path.splitext(image_filename)[0] + '.txt'\n",
    "                    output_path = os.path.join(output_dir, output_filename)\n",
    "\n",
    "                    # Записываем результат функции в текстовый файл\n",
    "                    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                        f.write(result)\n",
    "                    print(f'Результат для {image_filename} сохранен в {output_filename}')\n",
    "            except Exception as e:\n",
    "                print(f'Ошибка при обработке {image_filename}: {e}')\n",
    "\n",
    "# Пример использования функции\n",
    "input_dir = '../data/interim/images/'  # Укажи путь к папке с изображениями\n",
    "# output_dir = os.path.join(input_dir, 'txt_files')  # Создаем новую папку рядом с исходной\n",
    "output_dir = '../data/interim/texts/'\n",
    "\n",
    "create_texts_from_images(input_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a67d8a0-5a0f-418a-b84c-810c39e7eb0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл: page_1.txt содержит 512 токенов\n",
      "Файл: page_10.txt содержит 495 токенов\n",
      "Файл: page_11.txt содержит 728 токенов\n",
      "Файл: page_12.txt содержит 588 токенов\n",
      "Файл: page_13.txt содержит 603 токенов\n",
      "Файл: page_14.txt содержит 718 токенов\n",
      "Файл: page_15.txt содержит 634 токенов\n",
      "Файл: page_16.txt содержит 521 токенов\n",
      "Файл: page_17.txt содержит 663 токенов\n",
      "Файл: page_18.txt содержит 681 токенов\n",
      "Файл: page_19.txt содержит 518 токенов\n",
      "Файл: page_2.txt содержит 558 токенов\n",
      "Файл: page_20.txt содержит 841 токенов\n",
      "Файл: page_3.txt содержит 531 токенов\n",
      "Файл: page_4.txt содержит 482 токенов\n",
      "Файл: page_5.txt содержит 345 токенов\n",
      "Файл: page_6.txt содержит 583 токенов\n",
      "Файл: page_7.txt содержит 504 токенов\n",
      "Файл: page_8.txt содержит 639 токенов\n",
      "Файл: page_9.txt содержит 575 токенов\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tiktoken\n",
    "\n",
    "def count_tokens_in_text_files(input_dir):\n",
    "    # Инициализируем токенизатор от tiktoken (например, для модели GPT-3.5 или GPT-4)\n",
    "    tokenizer = tiktoken.get_encoding(\"cl100k_base\")  # Используем токенизатор для модели OpenAI (можно настроить под другую модель)\n",
    "\n",
    "    # Проходим по каждому файлу в указанной директории\n",
    "    for text_filename in os.listdir(input_dir):\n",
    "        # Полный путь к текстовому файлу\n",
    "        text_path = os.path.join(input_dir, text_filename)\n",
    "\n",
    "        # Проверяем, что файл имеет расширение .txt\n",
    "        if text_filename.lower().endswith('.txt'):\n",
    "            try:\n",
    "                # Открываем и читаем содержимое файла с кодировкой UTF-8\n",
    "                with open(text_path, 'r', encoding='utf-8') as file:\n",
    "                    text_content = file.read()\n",
    "\n",
    "                # Токенизируем текст и подсчитываем количество токенов\n",
    "                tokens = tokenizer.encode(text_content)\n",
    "                num_tokens = len(tokens)\n",
    "\n",
    "                # Выводим результат\n",
    "                print(f'Файл: {text_filename} содержит {num_tokens} токенов')\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f'Ошибка при обработке файла {text_filename}: {e}')\n",
    "\n",
    "# Пример использования функции\n",
    "input_dir = '../data/interim/texts/'  # Укажи путь к папке с текстовыми файлами\n",
    "count_tokens_in_text_files(input_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9f4a9e-1511-44ef-b2e2-40d26d24e1bd",
   "metadata": {},
   "source": [
    "### RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "32e34716-a041-4c5a-9a87-6316ec60121c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2e218512-18f0-4edb-a5da-065b4e3964b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружен файл: page_1.txt\n",
      "Загружен файл: page_10.txt\n",
      "Загружен файл: page_11.txt\n",
      "Загружен файл: page_12.txt\n",
      "Загружен файл: page_13.txt\n",
      "Загружен файл: page_14.txt\n",
      "Загружен файл: page_15.txt\n",
      "Загружен файл: page_16.txt\n",
      "Загружен файл: page_17.txt\n",
      "Загружен файл: page_18.txt\n",
      "Загружен файл: page_19.txt\n",
      "Загружен файл: page_2.txt\n",
      "Загружен файл: page_20.txt\n",
      "Загружен файл: page_3.txt\n",
      "Загружен файл: page_4.txt\n",
      "Загружен файл: page_5.txt\n",
      "Загружен файл: page_6.txt\n",
      "Загружен файл: page_7.txt\n",
      "Загружен файл: page_8.txt\n",
      "Загружен файл: page_9.txt\n",
      "Загружено документов: 20\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "\n",
    "def load_all_documents_from_folder(folder_path):\n",
    "    documents = []\n",
    "    \n",
    "    # Проходим по каждому файлу в указанной папке\n",
    "    for filename in os.listdir(folder_path):\n",
    "        # Полный путь к файлу\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Проверяем, что это текстовый файл\n",
    "        if filename.lower().endswith('.txt'):\n",
    "            try:\n",
    "                # Используем TextLoader для загрузки содержимого файла\n",
    "                loader = TextLoader(file_path, encoding='utf-8')  # Задаем кодировку, если нужно\n",
    "                documents.extend(loader.load())  # Загружаем содержимое и добавляем в список\n",
    "                print(f'Загружен файл: {filename}')\n",
    "            except Exception as e:\n",
    "                print(f'Ошибка при загрузке файла {filename}: {e}')\n",
    "    \n",
    "    return documents\n",
    "\n",
    "# Пример использования функции\n",
    "folder_path = '../data/interim/texts' \n",
    "docs = load_all_documents_from_folder(folder_path)\n",
    "\n",
    "print(f'Загружено документов: {len(docs)}')\n",
    "\n",
    "# headers_to_split_on = [\n",
    "#     (\"#\", \"Header 1\"),\n",
    "#     (\"##\", \"Header 2\"),\n",
    "#     (\"###\", \"Header 3\"),\n",
    "# ]\n",
    "# markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "# splits = [markdown_splitter.split_text(document.page_content) for document in docs]\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1eef6a69-d342-4444-b7a9-23a65b7bda6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "def count_tokens(text):\n",
    "    tokens = tokenizer.encode(text)  # Токенизация текста\n",
    "    return len(tokens)\n",
    "\n",
    "chunk_size = 512\n",
    "chunk_overlap = 0\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size, chunk_overlap=chunk_overlap, length_function=count_tokens,\n",
    ")\n",
    "splits = text_splitter.split_documents(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6724bedb-0e69-49dc-9657-a94ac957a9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Chroma.from_documents(splits,\n",
    "                           HuggingFaceEmbeddings(model_name=\"intfloat/multilingual-e5-large\"),\n",
    "                            collection_name='rag-sber')\n",
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "af960695-35fc-4907-aaf5-924c24bfcf54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '../data/interim/texts\\\\page_18.txt'}, page_content='### Подготовка ИИ-кадров\\n- Обучение контенту и разработке специализированных программ:\\n  - **200 тыс. студентов** по контенту.\\n  - **711 студентов** по образовательным программам Сбера по ИИ.\\n- Участие в Уроке Цифры \"Искусственный интеллект в отраслях\": **2,8 млн школьников**. \\n\\n### Центр компетенций\\n- Сбер является Центром компетенций для реализации федерального соглашения по развитию высокотехнологичных направлений \"Искусственный интеллект\".'),\n",
       " Document(metadata={'source': '../data/interim/texts\\\\page_18.txt'}, page_content='# Искусственный интеллект в 2023 году: Ключевая информация\\n\\n### Результаты AI-трансформации\\n- **Финансовый эффект** от внедрения ИИ в 2023 году: **350+ млрд руб.**\\n- **Среднегодовой рост эффекта от ИИ (CAGR)** за 2020–2023 годы: **53%**\\n- **Количество сотрудников** в области данных и ИИ: **2,7 тыс.**\\n- **Модели ИИ**, внедренные в бизнес-процессы банка: **2 тыс. моделей**\\n\\n### Модели генеративного ИИ\\n- **GigaChat**\\n  - Сервис для взаимодействия с пользователями в формате диалога.\\n  - **Количество пользователей**: **2,6 млн**\\n  \\n- **Kandinsky**\\n  - Модель для генерации высококачественных изображений по текстовому описанию.\\n  - **Количество генераций**: **200+ млн изображений**\\n  \\n- **Kandinsky Video**\\n  - Первая в России модель для создания видео по текстовому описанию.\\n\\n### AI Journey\\n- Международная конференция **AI Journey** в 2023 году.\\n- **Просмотры трансляции**: **150 млн**\\n- **Спикеры**: более **200**\\n  \\n### Исследовательская деятельность\\n- Сотрудничество с вузами для разработки инструментов ИИ.\\n- Участие в научных публикациях: **93** статьи в Q1 2023 года.'),\n",
       " Document(metadata={'source': '../data/interim/texts\\\\page_12.txt'}, page_content='## Модели генеративного ИИ\\n- **Kandinsky**\\n- **GigaChat**\\n\\n---\\n\\nЭти данные подчеркивают стратегические достижения Сбера в области клиентских и корпоративных услуг, а также в технологическом и финансовом секторах.'),\n",
       " Document(metadata={'source': '../data/interim/texts\\\\page_16.txt'}, page_content='## Технологические инновации\\n- **Формирование режимов работы офисов** с помощью AI-инструментов.\\n- **Скорректированные графики** приема посетителей: 1,294 офиса.')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.get_relevant_documents(\"искусственный интеллект\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a89b6cc-13cb-4256-8bf4-958909422578",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sber-reports-rag",
   "language": "python",
   "name": "sber-reports-rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
